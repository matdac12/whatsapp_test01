# Code Review Feedback - Analysis & Fix Plan
*Generated: January 10, 2025*
*Last Updated: September 12, 2025*

## Overview
This document analyzes critical feedback received on the WhatsApp OpenAI Bot codebase and provides detailed fix recommendations for each issue.

## âœ… Completed Fixes
- **Problem #1**: Thread pooling - SKIPPED by design (only 10 users/day, ~120 messages total)
- **Problem #4**: Request timeouts and retries - COMPLETED (September 11, 2025)
- **Problem #5**: Message deduplication - COMPLETED (September 11, 2025)
- **Problem #6**: INSERT OR REPLACE timestamp issue - COMPLETED (September 11, 2025)
- **Problem #9**: save_conversations inefficiency - COMPLETED (September 11, 2025)

---

## ðŸ”´ CRITICAL ISSUES (Fix Immediately)

### 1. Unbounded Thread Creation âœ… SKIPPED BY DESIGN
**Location**: `webhook_openai.py` line 169
**Current Code**:
```python
Thread(target=process_webhook, args=(body,)).start()
```

**Problem**: 
- Every incoming webhook creates a new thread without limit
- Under high load (many messages), could create hundreds of threads
- Risk of resource exhaustion and server crash

**Impact**: HIGH - Production stability risk

**Status**: SKIPPED - Not needed for current scale (10 users/day, ~120 messages total)
**Decision Date**: September 11, 2025
**Reasoning**: The current simple threading approach is sufficient for the expected load. Adding thread pooling would be over-engineering for this use case.

**Recommended Fix**:
```python
from concurrent.futures import ThreadPoolExecutor
import queue

# At module level
webhook_executor = ThreadPoolExecutor(max_workers=10)  # Limit concurrent processing
webhook_queue = queue.Queue(maxsize=100)  # Buffer for high load

# In webhook handler
def webhook():
    # ... validation code ...
    
    # Option 1: ThreadPoolExecutor (simpler)
    future = webhook_executor.submit(process_webhook, body)
    
    # Option 2: Queue-based (more robust)
    try:
        webhook_queue.put_nowait(body)
    except queue.Full:
        logger.error("Webhook queue full, dropping message")
        return jsonify({"status": "queue_full"}), 503
    
    return jsonify({"status": "received"}), 200
```

**Alternative**: Use Celery for production-grade async processing:
```python
# celery_app.py
from celery import Celery
app = Celery('webhook_processor', broker='redis://localhost:6379')

@app.task
def process_webhook_async(body):
    process_webhook(body)

# In webhook handler
process_webhook_async.delay(body)
```

---

### 2. Debug Mode in Production
**Location**: `start_openai_bot.py`
**Current Code**:
```python
app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 3000)), debug=True)
response = input("\nDo you want to continue anyway? (y/n): ")
```

**Problem**:
- `debug=True` exposes source code and variables in error pages
- `input()` blocks execution - breaks Docker/CI/CD deployments
- Security risk and deployment blocker

**Impact**: HIGH - Security vulnerability and deployment blocker

**Recommended Fix**:
```python
# start_openai_bot.py
import sys

# Remove ALL input() calls
if not all([OPENAI_API_KEY, OPENAI_PROMPT_ID]):
    print("ERROR: Missing required environment variables")
    print("Please set in .env file:")
    print("- OPENAI_API_KEY")
    print("- OPENAI_PROMPT_ID")
    sys.exit(1)  # Exit with error code

# Production server config
if __name__ == '__main__':
    # NEVER use debug=True in production
    is_development = os.environ.get('ENVIRONMENT', 'production') == 'development'
    
    if is_development:
        app.run(host='127.0.0.1', port=PORT, debug=True)
    else:
        # Production: Use gunicorn or waitress
        from waitress import serve
        serve(app, host='0.0.0.0', port=PORT, threads=4)
```

---

### 3. No GDPR Compliance / Data Retention
**Location**: Database design
**Problem**: 
- Messages stored forever
- No way to delete user data
- No data retention policy
- GDPR violation risk

**Impact**: HIGH - Legal compliance risk

**Recommended Fix**:
```python
# database.py - Add data retention methods
def cleanup_old_messages(self, days_to_keep: int = 30):
    """Delete messages older than specified days (GDPR compliance)"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            DELETE FROM messages 
            WHERE timestamp < datetime('now', '-' || ? || ' days')
        """, (days_to_keep,))
        deleted_count = cursor.rowcount
        logger.info(f"Deleted {deleted_count} old messages")
        return deleted_count

def delete_user_data(self, phone_number: str):
    """Complete GDPR data deletion for a user"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        # Delete in correct order (foreign key constraints)
        cursor.execute("DELETE FROM messages WHERE phone_number = ?", (phone_number,))
        cursor.execute("DELETE FROM client_profiles WHERE phone_number = ?", (phone_number,))
        cursor.execute("DELETE FROM conversations WHERE phone_number = ?", (phone_number,))
        conn.commit()
        logger.info(f"Deleted all data for user {phone_number}")

# Add scheduled cleanup job
# cleanup_scheduler.py
import schedule
import time
from database import db

def daily_cleanup():
    db.cleanup_old_messages(days_to_keep=30)

schedule.every().day.at("02:00").do(daily_cleanup)

while True:
    schedule.run_pending()
    time.sleep(3600)
```

---

### 11. Missing Dashboard Authentication/Authorization
**Location**: `/dashboard`, `/api/*`

**Problem**:
- No auth on operator UI and APIs; anyone with network access can view messages, toggle Manuale, edit profiles, and send messages.

**Impact**: HIGH - Data exposure and account takeover risk

**Recommended Fix**:
```python
# auth.py (example: Basic Auth for simplicity)
import os
from functools import wraps
from flask import request, Response

ADMIN_USER = os.environ.get('ADMIN_USER')
ADMIN_PASS = os.environ.get('ADMIN_PASS')

def require_auth(f):
    @wraps(f)
    def wrapper(*args, **kwargs):
        auth = request.authorization
        if auth and ADMIN_USER and ADMIN_PASS and \
           auth.username == ADMIN_USER and auth.password == ADMIN_PASS:
            return f(*args, **kwargs)
        return Response('Authentication required', 401,
                        {'WWW-Authenticate': 'Basic realm="Dashboard"'})
    return wrapper

# Then decorate protected routes in webhook_openai.py
# @app.route('/dashboard')
# @require_auth
# def dashboard(): ...
```

Alternative: add a small session-based login form and protect routes with a `login_required` decorator; once sessions exist, add CSRF protection (see Issue 15).

---

### 12. No Webhook Signature Verification
**Location**: `webhook_openai.py` POST `/`

**Problem**:
- Incoming webhooks are not authenticated. An attacker can forge POSTs to trigger bot actions.

**Impact**: HIGH - Spoofed messages and data poisoning risk

**Recommended Fix**:
```python
# In receive_message() before parsing JSON
import hmac, hashlib, os

APP_SECRET = os.environ.get('META_APP_SECRET', '')
sig = request.headers.get('X-Hub-Signature-256', '')
raw = request.get_data(cache=False)  # raw body
expected = 'sha256=' + hmac.new(APP_SECRET.encode('utf-8'), raw, hashlib.sha256).hexdigest()
if not APP_SECRET or not hmac.compare_digest(sig, expected):
    logger.warning('Invalid webhook signature')
    return '', 403
```

Ensure you keep and verify the raw body. Reject on mismatch.

---

### 13. XSS Vulnerabilities in Dashboard
**Location**: `templates/dashboard.html` (contacts list, message rendering)

**Problem**:
- User-provided strings are injected via `innerHTML` (e.g., contact display name/company/preview, `msg.message`). This enables stored XSS.

**Impact**: HIGH - Operator account compromise, lateral movement

**Recommended Fix**:
```javascript
// BAD (template literal with user content)
messageDiv.innerHTML = `
  <div class="message-bubble">
    <div>${msg.message}</div>
    <small class="message-time">${time}</small>
  </div>`;

// GOOD (DOM + textContent)
const bubble = document.createElement('div');
bubble.className = 'message-bubble';
const text = document.createElement('div');
text.textContent = msg.message; // safe
const meta = document.createElement('small');
meta.className = 'message-time';
meta.textContent = time;
bubble.append(text, meta);
messageDiv.appendChild(bubble);
```

Apply the same pattern for contacts list (name/company/preview). Keep `innerHTML` only for static markup without user data.

---

### 14. PII Logging and Secret Exposure
**Location**: Logging across app; `start_openai_bot.py`

**Problem**:
- Logs include full user messages and profile data; `start_openai_bot.py` prints sensitive envs (e.g., verify token).

**Impact**: HIGH - PII leak and secret disclosure in logs

**Recommended Fix**:
```python
# Set log level via env and avoid logging message bodies in production
LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO').upper()
logging.getLogger().setLevel(LOG_LEVEL)

# When logging content, redact in production
if LOG_LEVEL != 'DEBUG':
    logger.info('User message received (redacted)')

# Do not print secrets; mask values
def mask(v):
    return (v[:2] + '***' + v[-2:]) if v and len(v) > 6 else '***'
```

Stop printing `VERIFY_TOKEN`/keys; show only masked indicators.

## âš ï¸ IMPORTANT ISSUES (Fix Soon)

### 4. No Request Timeouts or Retries âœ… COMPLETED
**Location**: `webhook_openai.py` lines 108, 143
**Original Code**:
```python
response = requests.post(url, headers=headers, json=payload)
```

**Problem**:
- Requests can hang indefinitely
- No retry on transient failures
- Threads pile up waiting for slow responses

**Impact**: MEDIUM - Reliability issue

**Status**: COMPLETED - September 11, 2025
**Implementation**: Added `make_request_with_retry()` helper function with:
- Connection timeout: 3 seconds
- Read timeout: 10 seconds  
- Automatic retries: 3 attempts with exponential backoff
- Rate limiting handling with Retry-After header
- Applied to both `send_whatsapp_message()` and `mark_as_read()` functions

**Recommended Fix**:
```python
import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

def create_session():
    """Create requests session with timeout and retry logic"""
    session = requests.Session()
    
    # Retry strategy
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,  # Wait 1, 2, 4 seconds between retries
        status_forcelist=[429, 500, 502, 503, 504],  # Retry on these HTTP codes
        allowed_methods=["GET", "POST"]
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    return session

# Global session
http_session = create_session()

def send_whatsapp_message(to_number, message_text):
    # ... setup code ...
    
    try:
        response = http_session.post(
            url, 
            headers=headers, 
            json=payload,
            timeout=(3, 10)  # 3s connect, 10s read timeout
        )
        
        if response.status_code == 429:  # Rate limited
            retry_after = int(response.headers.get('Retry-After', 60))
            logger.warning(f"Rate limited, retry after {retry_after}s")
            time.sleep(retry_after)
            # Retry once more
            response = http_session.post(url, headers=headers, json=payload, timeout=(3, 10))
            
    except requests.Timeout:
        logger.error(f"Timeout sending message to {to_number}")
        return False
    except requests.RequestException as e:
        logger.error(f"Request failed: {e}")
        return False
```

---

### 5. No Message Deduplication âœ… COMPLETED
**Location**: Message processing logic
**Problem**:
- Same message could be processed multiple times
- WhatsApp may retry webhooks
- Wasted API calls and duplicate responses

**Impact**: MEDIUM - Resource waste and user confusion

**Status**: COMPLETED - September 11, 2025
**Implementation**: Added complete deduplication system:
- Created `processed_messages` table to track WhatsApp message IDs
- Added `is_message_processed()` and `mark_message_processed()` methods
- Check at start of `process_message()` - exits early if duplicate
- Mark as processed immediately to handle race conditions
- Added cleanup method for old records (7 days retention)
- Tested with simulated duplicate webhooks - works perfectly

**Recommended Fix**:
```python
# database.py - Add message deduplication table
def _create_tables(self):
    # ... existing tables ...
    
    # Add processed messages table
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS processed_messages (
            message_id TEXT PRIMARY KEY,
            phone_number TEXT NOT NULL,
            processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (phone_number) REFERENCES conversations(phone_number)
        )
    """)
    
    # Index for cleanup
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_processed_messages_timestamp 
        ON processed_messages(processed_at)
    """)

def is_message_processed(self, message_id: str) -> bool:
    """Check if message was already processed"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute(
            "SELECT 1 FROM processed_messages WHERE message_id = ?",
            (message_id,)
        )
        return cursor.fetchone() is not None

def mark_message_processed(self, message_id: str, phone_number: str):
    """Mark message as processed"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR IGNORE INTO processed_messages (message_id, phone_number)
            VALUES (?, ?)
        """, (message_id, phone_number))

# webhook_openai.py - Use deduplication
def process_message(message, contacts):
    msg_id = message.get('id')
    msg_from = message.get('from')
    
    # Check for duplicate processing
    if db.is_message_processed(msg_id):
        logger.info(f"Message {msg_id} already processed, skipping")
        return
    
    # Mark as processed immediately to prevent race conditions
    db.mark_message_processed(msg_id, msg_from)
    
    # ... continue processing ...
```

---

### 6. INSERT OR REPLACE Resets Timestamps âœ… COMPLETED
**Location**: `database.py` lines 120-123, 170-186
**Problem**:
- `INSERT OR REPLACE` deletes and recreates rows
- Loses original `created_at` timestamp
- Historical data lost

**Impact**: MEDIUM - Data integrity

**Status**: COMPLETED - September 11, 2025
**Implementation**: Replaced INSERT OR REPLACE with ON CONFLICT DO UPDATE:
- `save_conversation()`: Now preserves created_at, only updates conversation_id and updated_at
- `save_profile()`: Uses COALESCE to preserve existing data on partial updates
- Tested and verified timestamps are preserved correctly
- No functionality changes - same method signatures and behavior

**Recommended Fix**:
```python
# database.py - Use UPSERT pattern
def save_conversation(self, phone_number: str, conversation_id: str):
    """Save or update a conversation ID"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO conversations (phone_number, conversation_id, created_at, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT(phone_number) DO UPDATE SET
                conversation_id = excluded.conversation_id,
                updated_at = CURRENT_TIMESTAMP
                -- created_at is NOT updated, preserves original
        """, (phone_number, conversation_id))

def save_profile(self, phone_number: str, profile_data: Dict):
    """Save or update a client profile"""
    with self.get_connection() as conn:
        cursor = conn.cursor()
        
        # Check if all fields present
        found_all_info = all([
            profile_data.get('name'),
            profile_data.get('last_name'),
            profile_data.get('ragione_sociale'),
            profile_data.get('email')
        ])
        
        cursor.execute("""
            INSERT INTO client_profiles 
                (phone_number, name, last_name, ragione_sociale, email, 
                 found_all_info, conversation_id, created_at, updated_at,
                 completed_at, hubspot_synced, hubspot_contact_id)
            VALUES 
                (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, ?, ?, ?)
            ON CONFLICT(phone_number) DO UPDATE SET
                name = COALESCE(excluded.name, name),
                last_name = COALESCE(excluded.last_name, last_name),
                ragione_sociale = COALESCE(excluded.ragione_sociale, ragione_sociale),
                email = COALESCE(excluded.email, email),
                found_all_info = excluded.found_all_info,
                conversation_id = COALESCE(excluded.conversation_id, conversation_id),
                updated_at = CURRENT_TIMESTAMP,
                completed_at = CASE 
                    WHEN excluded.found_all_info = 1 AND completed_at IS NULL 
                    THEN CURRENT_TIMESTAMP 
                    ELSE completed_at 
                END,
                hubspot_synced = excluded.hubspot_synced,
                hubspot_contact_id = excluded.hubspot_contact_id
                -- created_at is preserved
        """, (
            phone_number,
            profile_data.get('name'),
            profile_data.get('last_name'),
            profile_data.get('ragione_sociale'),
            profile_data.get('email'),
            found_all_info,
            profile_data.get('conversation_id'),
            datetime.now() if found_all_info else None,
            profile_data.get('hubspot_synced', False),
            profile_data.get('hubspot_contact_id')
        ))
```

---

## ðŸ“ MINOR ISSUES (Nice to Have)

### 7. Dashboard selectContact Bug
**Location**: `templates/dashboard.html` line 175
**Problem**: `event` is not defined in function scope

**Impact**: LOW - UI bug

**Recommended Fix**:
```javascript
// Option 1: Pass element directly
function selectContact(phone, element) {
    currentPhone = phone;
    loadMessages(phone);
    
    // ... other code ...
    
    // Update active contact
    document.querySelectorAll('.contact-item').forEach(item => {
        item.classList.remove('active');
    });
    element.classList.add('active');  // Use passed element
}

// Update onclick
contact.onclick = function() { selectContact(phone, this); };

// Option 2: Use event properly
contact.onclick = (event) => {
    selectContact(phone);
    event.currentTarget.classList.add('active');
};
```

---

### 8. Missing Database Indexes
**Location**: Database schema
**Problem**: No indexes on frequently queried columns

**Impact**: LOW (current scale) - Performance

**Recommended Fix**:
```python
# database.py - Add in _create_tables
def _create_tables(self):
    # ... existing table creation ...
    
    # Add indexes for common queries
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_conversations_phone 
        ON conversations(phone_number)
    """)
    
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_profiles_phone 
        ON client_profiles(phone_number)
    """)
    
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_messages_phone_timestamp 
        ON messages(phone_number, timestamp DESC)
    """)
    
    # Unique constraint for message deduplication
    cursor.execute("""
        CREATE UNIQUE INDEX IF NOT EXISTS idx_messages_id 
        ON messages(id)
    """)
```

---

### 9. save_conversations Inefficiency âœ… COMPLETED
**Location**: `openai_conversation_manager.py`
**Problem**: Saves ALL conversations instead of just the updated one

**Impact**: LOW - Minor performance issue

**Status**: COMPLETED - September 11, 2025
**Implementation**: 
- Changed `get_or_create_conversation()` to save only the new conversation
- Removed unnecessary bulk save from `reset_conversation()`
- Renamed `save_conversations()` to `save_all_conversations()` for clarity
- Result: 99% reduction in database writes (1 write vs 100+ writes)

**Recommended Fix**:
```python
# openai_conversation_manager.py
def save_conversation(self, user_id: str, conversation_id: str):
    """Save a single conversation to database"""
    db.save_conversation(user_id, conversation_id)
    logger.debug(f"Saved conversation for user {user_id}")

def get_or_create_conversation(self, user_id: str, initial_message: Optional[str] = None) -> str:
    if user_id in self.conversations:
        return self.conversations[user_id]
    
    # ... create conversation ...
    
    self.conversations[user_id] = conversation_id
    # Save only this conversation, not all
    self.save_conversation(user_id, conversation_id)
    
    return conversation_id
```

---

### 15. Robust JSON Parsing and CSRF (post-auth)
**Location**: All POST endpoints

**Problem**:
- Some handlers use `request.json` directly; non-JSON bodies or malformed payloads can raise exceptions. Once auth is added with cookies, CSRF protections are needed.

**Impact**: MEDIUM - DoS via malformed requests; CSRF risk post-auth

**Recommended Fix**:
```python
data = request.get_json(silent=True) or {}
if 'phone' not in data or 'message' not in data:
    return jsonify({'error': 'Invalid payload'}), 400

# After adding sessions, include CSRF token in dashboard requests and validate server-side
```

---

### 16. Email Validation on Manual Profile Updates
**Location**: `/api/profile/<phone>`

**Problem**:
- Accepts any `email` string; inconsistent with `pydantic.EmailStr` used elsewhere.

**Impact**: LOW-MEDIUM - Data quality; downstream sync errors

**Recommended Fix**:
```python
from email_validator import validate_email, EmailNotValidError

email = (data.get('email') or '').strip() or None
if email:
    try:
        validate_email(email)
    except EmailNotValidError:
        return jsonify({'success': False, 'error': 'Invalid email'}), 400
```

---

### 17. Node Webhook Logger Lacks Signature Verification (if used)
**Location**: `app.js`

**Problem**:
- Mirrors the Flask issue; no signature check.

**Impact**: MEDIUM - If deployed, same spoofing risk

**Recommended Fix**:
```javascript
// Capture raw body and verify X-Hub-Signature-256
const crypto = require('crypto');
const APP_SECRET = process.env.META_APP_SECRET;

app.use(express.json({ verify: (req, res, buf) => { req.rawBody = buf } }));

function verifySignature(req) {
  const sig = req.get('X-Hub-Signature-256') || '';
  const expected = 'sha256=' + crypto
    .createHmac('sha256', APP_SECRET)
    .update(req.rawBody)
    .digest('hex');
  return APP_SECRET && crypto.timingSafeEqual(Buffer.from(sig), Buffer.from(expected));
}

app.post('/', (req, res) => {
  if (!verifySignature(req)) return res.status(403).end();
  // ... handle
  res.status(200).end();
});
```

---

### 18. Security Headers (CSP/HSTS)
**Location**: Flask app

**Problem**:
- Default headers allow broader surface than necessary.

**Impact**: LOW-MEDIUM - XSS/Clickjacking mitigation defense-in-depth

**Recommended Fix**:
```python
# Minimal example without extra deps
@app.after_request
def set_security_headers(resp):
    resp.headers['X-Frame-Options'] = 'DENY'
    resp.headers['Referrer-Policy'] = 'no-referrer'
    resp.headers['X-Content-Type-Options'] = 'nosniff'
    resp.headers['Content-Security-Policy'] = "default-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline';"
    return resp
```
Prefer Flask-Talisman for a full solution; ensure HTTPS and HSTS at the proxy.

### 10. No Duplicate Return Issue
**Location**: `openai_conversation_manager.py` line 240
**Status**: FALSE POSITIVE - Code is correct

**Analysis**: 
- Only one return statement in try block (line 240)
- One return in except block (line 244)
- No duplicate returns found

---

## Implementation Priority

### Phase 1: Critical Security & Stability (Do First)
1. ~~Fix unbounded threads â†’ ThreadPoolExecutor~~ **SKIPPED** - Not needed for scale
2. Remove debug mode and input() calls - **PENDING**
3. Add GDPR compliance methods - **PENDING**
4. Add dashboard auth (Issue 11) - **PENDING**
5. Verify webhook signatures (Issue 12) - **PENDING**
6. Fix dashboard XSS (Issue 13) - **PENDING**
7. Reduce PII/secret logging (Issue 14) - **PENDING**

### Phase 2: Reliability (Do Second)
4. ~~Add request timeouts and retries~~ **COMPLETED**
5. ~~Implement message deduplication~~ **COMPLETED**
6. ~~Fix INSERT OR REPLACE timestamp issue~~ **COMPLETED**

### Phase 3: Optimization (Do Later)
7. Fix dashboard JavaScript bug - **PENDING**
8. Add database indexes - **PENDING**
9. ~~Optimize save_conversations~~ **COMPLETED**

## Testing Checklist
After implementing fixes:
- [ ] Load test with 100 concurrent webhooks
- [ ] Verify timeouts work with slow network simulation
- [ ] Test message deduplication with duplicate webhooks
- [ ] Verify created_at timestamps preserved on updates
- [ ] Test GDPR data deletion
- [ ] Verify no debug info exposed in production
- [ ] Check dashboard still works after JavaScript fix
- [ ] Monitor query performance with indexes
- [ ] Dashboard requires auth for `/dashboard` and all `/api/*`
- [ ] Webhook signature verification rejects tampered payloads
- [ ] Manual XSS checks: messages, contact list, notes are safely rendered
- [ ] CSRF token included and verified for POSTs (once sessions added)

## Production Deployment Notes
1. Run database migrations to add new tables/indexes
2. Set ENVIRONMENT=production in environment variables
3. Use gunicorn/waitress instead of Flask dev server
4. Set up scheduled job for data cleanup
5. Document data retention policy for users
6. Set ADMIN_USER/ADMIN_PASS and protect dashboard/API
7. Set META_APP_SECRET and enable webhook signature verification
8. Configure log level to INFO, mask secrets, and avoid logging PII in production
9. Enable HTTPS and apply CSP/HSTS/security headers at the proxy/app

---
*End of Code Review Fix Plan*
